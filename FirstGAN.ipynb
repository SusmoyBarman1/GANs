{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Conv2D, Conv2DTranspose, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n",
      "(60000, 28, 28, 1)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_images.dtype)\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images - 127.5)/127.5  # Normalize images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Reshape((7, 7, 256))) # current image size= 7 x 7 x 256\n",
    "    \n",
    "    model.add(Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))  # current image size= 7 x 7 x 128\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))  # current image size= 14 x 14 x 64\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'))  # current image size= 28 x 28 x 1\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19c8e7bcec8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYPElEQVR4nO2de4yV5bXGn8VwvwoyMw5XETGAoKAjtVRtrULRmli0HiXVaGsPNlXbJibnmJ6k9Y8mJefY0542p01RsdSqVC20NjVVQq1CqciAKMgoN0duA4PckTus88dsT6id91nTuew96fv8ksme2c+svd/59vfMvqx3rWXuDiHEPz+dSr0AIURxkNmFyASZXYhMkNmFyASZXYhM6FzMO+vRo4f37du3xfFmltQ6deL/t06dOtXi2wYAlrWI7ru1GY/Tp0+3OLasrIzq0XHp3JmfIidPnqQ6+9u7dOlCY6O/+8SJE1Rnj0t039FxidYWHTd2vkXnIjvmBw4cwJEjR5q8gVaZ3cymAfgfAGUAHnX3Wez3+/btixkzZrDbo/fHDmCPHj1o7L59+6jerVs3qrMHv3v37jQ2Oimjv/vw4cNUZ0T/XA8ePEj1s846i+q7d++mOjtuVVVVNPbDDz+k+rZt26jep0+fpFZRUUFj9+/fT/Vjx45RfcCAAVRn53LXrl1p7N69e5Pak08+mdRa/DLezMoA/C+A6wCMBTDDzMa29PaEEO1La96zTwKwwd03uftxAPMA3Ng2yxJCtDWtMftgAFvO+Hlr4bq/wcxmmlmNmdUcOXKkFXcnhGgNrTF7U280/+7TGHef7e7V7l4dva8WQrQfrTH7VgBDz/h5CIDtrVuOEKK9aI3ZlwMYZWYjzKwrgNsAPN82yxJCtDUtTr25+0kzuw/Ai2hMvc1x97dZjJnRlEOUE2aplCg9dejQIaqPGjWK6q+//npSGz58OI0tLy+n+saNG6nes2dPqrM0UF1dHY294YYbqL5kyRKq79mzh+qDBg1KatHbugMHDlB92rRpVH/nnXeSWpS2GzZsGNV79epF9Sg1x8716HwYOHBgUmN7C1qVZ3f3FwC80JrbEEIUB22XFSITZHYhMkFmFyITZHYhMkFmFyITZHYhMqGo9eynT5+m+fDjx4/TeFYqynLwQFyquXnzZqqPHDkyqb3xxhs09sILL6R6a2uj2R6C888/n8Y+++yzVB83bhzVI9atW5fUamtraeyYMWOo/qtf/YrqLB8d9RjYsWMH1aMS1qikmu1P6N27N41ljzcrKdYzuxCZILMLkQkyuxCZILMLkQkyuxCZILMLkQlFTb2ZGe3EGnVCZSWPUbfQ999/n+r9+/enOksLRrEffPAB1b/yla9Q/amnnqL6rl27ktqQIUNo7B133EH1qER27FjeY5Sl3t59910ay1JnAPDVr36V6gsWLEhqU6dOpbHR2qKOway0F+CPS5QGZqlY2m6d3qoQ4p8GmV2ITJDZhcgEmV2ITJDZhcgEmV2ITJDZhciEoubZAV5aGE3OZOV7mzZtorFR+WyUC2etf6MS1Cjnev/991N98uTJVGf3Hx3TuXPnUp2V9gLA4sWLqc4e7379+tHYqJX0vHnzqD5x4sSk9sQTT9DYqE310qVLqR61kmaty6PW4azElZVL65ldiEyQ2YXIBJldiEyQ2YXIBJldiEyQ2YXIBJldiEwoep6d5cp37txJYy+//PKktnz5chobtf6tqqqiOhuFu2LFChp78cUXU/2iiy6iOqtXB4ARI0YktahHwO2330716Lh++tOfpjrLCUd12127dqV6NG76+eefT2rXXnstjf3LX/5C9ehcvemmm6h+wQUXJLWoNTk7l9kxa5XZzawOwEEApwCcdPfq1tyeEKL9aItn9qvdnW8/E0KUHL1nFyITWmt2B/CSma0ws5lN/YKZzTSzGjOrOXLkSCvvTgjRUlr7Mv5T7r7dzCoALDSzd9z91TN/wd1nA5gNAJWVlXzAlhCi3WjVM7u7by9cNgBYAGBSWyxKCNH2tNjsZtbLzPp89D2AqQDWtNXChBBtS2texlcCWFDoU90ZwFPu/kcW4O44efJkUo96kLMxutFo4qi++MUXX6T69OnTk1rUs37JkiVUj+Lfe+89qrNx1D169KCxr7zyCtWjXHdDQwPV2WNWX19PY6Oe948//jjV2ajsrVu30tizzz6b6lHf+Oi4sFz5li1baCx7vJm/Wmx2d98EgO8WEUJ0GJR6EyITZHYhMkFmFyITZHYhMkFmFyITilri2qlTJ/Tu3TupR2WoR48eTWobNmygsVEZ6ejRo6nOSnPZGGoA6NOnD9WjMtRPfvKTVGdlpNGo6qhE9bnnnqP6eeedR/UoBcWIUlBRmWp5eXlSi9Kh+/btozpr2QzwElYAuOyyy1p834cPH05qrK24ntmFyASZXYhMkNmFyASZXYhMkNmFyASZXYhMkNmFyISi5tnNjOYBly1bRuNZ2WH//v1p7LZt26i+Zg0vxWe58Pnz59NYVpIIAF26dKF6NNL52WefTWosBw8ACxYsoPoDDzxA9YceeojqrDQ4GrPNxhoDwAsvvED1CRMmJDU2ShoALr30UqpHZcd//COt9qbtogtl40nq6uqSGnu89cwuRCbI7EJkgswuRCbI7EJkgswuRCbI7EJkgswuRCZYlG9sSyorK/22225L6t26daPx69atS2pRW+KhQ4dSfdy4cVT/4IP07Mrqaj689t1336X6+PHjqb5nzx6qV1ZWJrWoRXY0qrpnz55UX7x4MdXZaGPW6rk5RHl4lsv+xCc+QWNZC2wgbnv+hz/8gerXXHNNUmPnOcBHgH/ve99DXV1dk4l6PbMLkQkyuxCZILMLkQkyuxCZILMLkQkyuxCZILMLkQlFrWc/ceIEzYdHfeOHDRuW1K644goaG/WVX7RoEdWHDx+e1FgOHojz7FEenfWsB3iuPMoHRz3roz4AUd/4QYMGJbUDBw7Q2KlTp1I9qmffvn17Ujt48CCNffPNN6kexUfnMusr//rrr9NYNgvg+PHjSS18ZjezOWbWYGZrzrhugJktNLP1hUveOUIIUXKa8zL+FwCmfey6BwEscvdRABYVfhZCdGBCs7v7qwA+/jrzRgBzC9/PBfCFtl2WEKKtaekHdJXuXg8AhcuK1C+a2UwzqzGzmmPHjrXw7oQQraXdP41399nuXu3u1VGhixCi/Wip2XeaWRUAFC5bPqpTCFEUWmr25wHcWfj+TgC/a5vlCCHaizDPbmZPA/gMgIFmthXAdwHMAvCMmd0NYDOAW5pzZ926dcPIkSOTelRDzGa7r1+/nsayHuLNue9LLrkkqbE54ADw2c9+lurRLO+HH36Y6hUVyY9MsHfvXhob9Uf/05/+RPVoD8Bdd92V1Fj/cyDO8X/ta1+j+p///OekFvUgiM6HaF/GlVdeSfW1a9cmtaj3Asuls7nxodndfUZCSlffCyE6HNouK0QmyOxCZILMLkQmyOxCZILMLkQmFLXEFeDjaAcPHkxjWenf4cOHaWxUyslSFgCwevXqpFZbW0tjN2/eTPXJkydTPWrnPGfOnKTWo0cPGvv973+f6tHI5ldeeYXq3/jGN5IaS2cCfEQ3AHz5y1+m+j333JPUnn76aRo7ZswYqrP23UDcJpul7qLHjLXQZv7SM7sQmSCzC5EJMrsQmSCzC5EJMrsQmSCzC5EJMrsQmVDUkc3l5eU+ffr0pM7KXwFg9+7dSS0q5Yxy1VGZ6q9//eukdv/999PY/fv3U33jxo1Uj1omP/XUU0lt9uzZNDbqHrRv3z6qX3TRRVRnI5snTZpEYx955BGqn3XWWVRn+zaiPDpbNwCMGDGC6n/961+pznwQtZI+evRoUnviiSewY8cOjWwWImdkdiEyQWYXIhNkdiEyQWYXIhNkdiEyQWYXIhOKWs9uZujatWtSX7VqFY3v169fUuvevTuNjXKyUQ3xF7/4xaT229/+lsZOm/bxuZh/S6dO/H9u1PaYtUzu1asXje3Tpw/Vo+MajV1m46yjPQADBw6k+uWXX051tjfinHPOobFRf4NozHa0r2PlypVJLRqTxo5L585pS+uZXYhMkNmFyASZXYhMkNmFyASZXYhMkNmFyASZXYhMKHqevUuXLkm9f//+NJ7V3rN+2UCcLx4wYADVWV131Ds9Gi0c5XSvv/56qi9cuDCp3XrrrTT2jTfeoPqKFSuozkYyA3wsczTWOKqlZ3X8AHD77bcntSiHH42iXr58OdWjEeFbtmxJamw0OQBs2LAhqbEcffjMbmZzzKzBzNaccd1DZrbNzFYVvvjZKIQoOc15Gf8LAE1tAfuhu08ofPFWKkKIkhOa3d1fBcD3BgohOjyt+YDuPjN7q/AyP/lm28xmmlmNmdUcOXKkFXcnhGgNLTX7zwCMBDABQD2AH6R+0d1nu3u1u1dHxSZCiPajRWZ3953ufsrdTwN4BABvEyqEKDktMruZVZ3x43QAa1K/K4ToGIR9483saQCfATAQwE4A3y38PAGAA6gDcI+710d3VlFR4SzvG+XK2Xv+9957j8aee+65VJ83bx7V77vvvqTGcskA0NDQQPWoZ33U233t2rVJ7YILLqCxUZ49Om4s5wsA48ePT2pRLXx0348//jjVZ82aldSiWnpWFw7Ej0nUT5/9bdFnW2zOwMsvv4y9e/c2aaRwU427z2ji6seiOCFEx0LbZYXIBJldiEyQ2YXIBJldiEyQ2YXIhKKWuHbu3Jm2dI7KKVkr6XvvvZfGLlu2jOqf//znqc5SlNdeey2NfewxnrxoTUtkgKcFH330URp73XXXUT1q7x2VqbKWyydOnKCx0Vjln/zkJ1Rn6bXhw4fT2G3btlH961//OtVfeuklqrMW21G59WWXXZbU2LhnPbMLkQkyuxCZILMLkQkyuxCZILMLkQkyuxCZILMLkQlhiWtbcs455zhr7xt1svnwww+TWlRmGrXnjcprKyoqklpUJjpu3DiqRyObo3JKNrKZ7U0AeL4XAK666iqqHzx4kOpDhgxJaqtXr6axrO04EI9NLisrS2qDBw+msbt376Z61Jo8KnFlx+X3v/89jWWlwUuXLsX+/fubPJn1zC5EJsjsQmSCzC5EJsjsQmSCzC5EJsjsQmSCzC5EJhS1nh3g+eyamhoaO3HixKR29tln09ioNnrNGt76nuX47777bhr7zjvvUD3K2UY5X/a3T5rE53d85zvfofqPf/xjqrM21gBvkx2Not6+fTvVN23aRPXzzjsvqUUjlX/6059SfdeuXVQfPXo01dkegeh8mDJlSlKrra1NanpmFyITZHYhMkFmFyITZHYhMkFmFyITZHYhMkFmFyITOlQ9e1SffPjw4aR27NgxGhvlLqORzyy3GdV0s175QNzTPhofzOq2o8d35cqVVI/68b/22mtUZ33ML7zwQho7YsQIqkf99K+++uqk9v7779PYaH/C/v37qR6N6Wb17mxPBwBs3rw5qb322mstr2c3s6Fm9rKZ1ZrZ22b2zcL1A8xsoZmtL1z2j25LCFE6mvMy/iSAB9x9DIDLAdxrZmMBPAhgkbuPArCo8LMQooMSmt3d6919ZeH7gwBqAQwGcCOAuYVfmwvgC+20RiFEG/APfUBnZucCmAhgGYBKd68HGv8hAGiySZuZzTSzGjOrYe+5hRDtS7PNbma9AfwGwLfcPd3x7mO4+2x3r3b36p49e7ZkjUKINqBZZjezLmg0+pPuPr9w9U4zqyroVQD4x49CiJISpt6ssSZ1LoA97v6tM67/LwC73X2WmT0IYIC7/xu7rfLycr/55puTelVVFV3L1q1bWxwbvYWI0n4svVZZWUlj9+3bR/Vhw4ZRPWr3fMsttyS1Z555hsZGo4mHDh1K9a5du1KdpZGi0t0o9cbaewPAoUOHktq6detobPR33XDDDVTfsmUL1dk5EbVU79WrV1L70Y9+hC1btjSZemtOPfunANwBYLWZrSpc920AswA8Y2Z3A9gMIH3GCSFKTmh2d18CINVx4pq2XY4Qor3QdlkhMkFmFyITZHYhMkFmFyITZHYhMqGoJa6VlZU+Y8aMpB6VoQ4cODCpbdy4kca2ZrQwwPOuO3fupLHnn38+1aMy0759+1KdjXxmrZyjWCDOhUelnuxvj0Yynzp1iurR2lh57cUXX0xjozx7lKcfNGgQ1SdPnpzU3nrrLRp7/PjxpPbcc8+hoaFBI5uFyBmZXYhMkNmFyASZXYhMkNmFyASZXYhMkNmFyISijmw2M9oWOWqZfOBAukFOVNvM2goDcc05azVdX19PY6+88kqqRy2VozbZrGY82l/wpS99ieo///nPqd67d2+qsz4Dn/vc52jsm2++SfUVK1ZQfdSoUUktqtOPWkFH46ZPnDhBddab4eTJkzSW5fDZ3gU9swuRCTK7EJkgswuRCTK7EJkgswuRCTK7EJkgswuRCUWtZ6+oqPBbb701qffvzwfBLl68OKlFfd+jXHaUjx43blxSO3LkCI2NRvBGPcajPQKsnp7tTQCAXbt2Ub1Pnz5Uj+rhWT45ynVHj8nSpUupzo7bhg0baOz48eOpvmPHDqpHe0bYSOjofGA+mTt3Lurr61XPLkTOyOxCZILMLkQmyOxCZILMLkQmyOxCZILMLkQmhPXsZjYUwC8BnAPgNIDZ7v4/ZvYQgH8F8FGi9tvu/kJwWygrK0vqUU545MiRSW3MmDE0Nsp1X3rppVSvq6tLatFs+KhvfNT/PJot361bt6R29OhRGhv1R49qyln/c4DXdb/99ts0NppbP3bsWKqzXPdNN91EY2tra6l+zTV8gPH69eupzvZGRPPZBwwYkNSYv5rTvOIkgAfcfaWZ9QGwwswWFrQfuvvDzbgNIUSJac589noA9YXvD5pZLYDB7b0wIUTb8g+9ZzezcwFMBLCscNV9ZvaWmc0xsyb38JnZTDOrMbOaaFupEKL9aLbZzaw3gN8A+Ja7HwDwMwAjAUxA4zP/D5qKc/fZ7l7t7tXRexEhRPvRLLObWRc0Gv1Jd58PAO6+091PuftpAI8ASO/sF0KUnNDsZmYAHgNQ6+7/fcb1Z34EPR3AmrZfnhCirQhLXM3sCgCLAaxGY+oNAL4NYAYaX8I7gDoA9xQ+zEtSXl7uN998c1KP2kGztEJUshiVYrJ0BsDb90atpFnaDuAtj4G4LfHatWuTWpSeitJ+/fr1o/qaNfx//PDhw5NaNOo6SutF46IZ0bjo6JhHxy2KZyOjN23aRGPZKOv58+dj165dTZa4NufT+CUAmgqmOXUhRMdCO+iEyASZXYhMkNmFyASZXYhMkNmFyASZXYhMKOrI5rKyMvTt2zepR6Wcjft7mibKm/bq1Yvqe/fupTpra3z8+HEaO2HChBbfdnNun4107t69O42dOHEi1aOc75QpU6jO8s2jR4+msYcOHaJ6lOtm+zai8yUqiWbnMRCPXWZEZcfsfGAe0TO7EJkgswuRCTK7EJkgswuRCTK7EJkgswuRCTK7EJlQ1JHNZrYLwPtnXDUQwAdFW8A/RkddW0ddF6C1tZS2XNtwdy9vSiiq2f/uzs1q3L26ZAsgdNS1ddR1AVpbSynW2vQyXohMkNmFyIRSm312ie+f0VHX1lHXBWhtLaUoayvpe3YhRPEo9TO7EKJIyOxCZEJJzG5m08zsXTPbYGYPlmINKcyszsxWm9kqM6sp8VrmmFmDma0547oBZrbQzNYXLpucsVeitT1kZtsKx26VmV1forUNNbOXzazWzN42s28Wri/psSPrKspxK/p7djMrA7AOwBQAWwEsBzDD3dOTDoqImdUBqHb3km/AMLOrABwC8Et3H1e47j8B7HH3WYV/lP3d/d87yNoeAnCo1GO8C9OKqs4cMw7gCwDuQgmPHVnXv6AIx60Uz+yTAGxw903ufhzAPAA3lmAdHR53fxXAno9dfSOAuYXv56LxZCk6ibV1CNy93t1XFr4/COCjMeMlPXZkXUWhFGYfDGDLGT9vRcea9+4AXjKzFWY2s9SLaYLKj8ZsFS75zKziE47xLiYfGzPeYY5dS8aft5ZSmL2pJlkdKf/3KXe/BMB1AO4tvFwVzaNZY7yLRRNjxjsELR1/3lpKYfatAIae8fMQANtLsI4mcffthcsGAAvQ8UZR7/xogm7hsqHE6/l/OtIY76bGjKMDHLtSjj8vhdmXAxhlZiPMrCuA2wA8X4J1/B1m1qvwwQnMrBeAqeh4o6ifB3Bn4fs7AfyuhGv5GzrKGO/UmHGU+NiVfPy5uxf9C8D1aPxEfiOA/yjFGhLrOg/Am4Wvt0u9NgBPo/Fl3Qk0viK6G8DZABYBWF+4HNCB1vYEGkd7v4VGY1WVaG1XoPGt4VsAVhW+ri/1sSPrKspx03ZZITJBO+iEyASZXYhMkNmFyASZXYhMkNmFyASZXYhMkNmFyIT/AzPEcU3nS3quAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = create_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Discriminator\n",
    "\n",
    "The discriminator is a CNN-Based image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = create_discriminator_model()\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00032171]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake(generated) images to an array of 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    \n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    \n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss\n",
    "\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminator decisions on the generated images to an array of 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    \n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers for discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
