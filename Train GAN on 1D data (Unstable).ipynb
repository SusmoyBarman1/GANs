{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, ones, hstack\n",
    "from numpy.random import rand, randn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator model\n",
    "\n",
    "def define_generator(latent_dim, n_outputs=2):\n",
    "    generator_model = Sequential(name = 'Generator_Model')\n",
    "    generator_model.add(Dense(15, \n",
    "                              activation='relu',\n",
    "                              kernel_initializer = 'he_uniform',\n",
    "                              input_dim = latent_dim))\n",
    "    \n",
    "    generator_model.add(Dense(n_outputs, activation='linear'))\n",
    "    \n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standalone discriminator model\n",
    "\n",
    "def define_discriminator_model(n_inputs=2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25,\n",
    "                    activation='relu',\n",
    "                    kernel_initializer = 'he_uniform',\n",
    "                    input_dim = n_inputs))\n",
    "    \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    # connect them\n",
    "    gan = Sequential()\n",
    "    \n",
    "    # add generator\n",
    "    gan.add(generator)\n",
    "    \n",
    "    # add discriminator\n",
    "    gan.add(discriminator)\n",
    "    \n",
    "    # compile model\n",
    "    gan.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam')\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n real samples with class labels\n",
    "\n",
    "def generate_real_samples(n):\n",
    "    # generate inputs in [-0.5, 0.5]\n",
    "    X1 = rand(n) - 0.5\n",
    "    # generate outputs X^2\n",
    "    X2 = X1 * X1\n",
    "    \n",
    "    X1 = X1.reshape(n, 1)\n",
    "    X2 = X2.reshape(n, 1)\n",
    "    \n",
    "    # stack array\n",
    "    X = hstack((X1, X2))\n",
    "    \n",
    "    # generate class labels\n",
    "    y = ones((n, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "\n",
    "def generate_latent_points(latent_dim, n):\n",
    "    x_input = randn(latent_dim * n)\n",
    "    x_input = x_input.reshape((n, latent_dim))\n",
    "    \n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples and plot the result\n",
    "\n",
    "def generate_fake_samples(gen, latent_dim, n):\n",
    "    \n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "    \n",
    "    # predict output\n",
    "    X = gen.predict(x_input)\n",
    "    # create class labels\n",
    "    y = zeros((n, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the discriminator and plot real and fake points\n",
    "\n",
    "def summarize_performance(epoch, gen, dis, latent_dim, n=100):\n",
    "    # prepare real samples\n",
    "    x_real, y_real = generate_real_samples(n)\n",
    "    \n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = dis.evaluate(x_real, y_real, verbose=0)\n",
    "    \n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(gen, latent_dim, n)\n",
    "    \n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = dis.evaluate(x_fake, y_fake, verbose=0)\n",
    "    \n",
    "    print(epoch, acc_real, acc_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "\n",
    "def train_gan(gen, dis, gan, latent_dim, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "    \n",
    "    half_batch = int(n_batch/2)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "        # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(gen, latent_dim, half_batch)\n",
    "        \n",
    "        # update discriminator\n",
    "        dis.train_on_batch(x_real, y_real)\n",
    "        dis.train_on_batch(x_fake, y_fake)\n",
    "        \n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        gan.train_on_batch(x_gan, y_gan)\n",
    "        \n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval ==0:\n",
    "            summarize_performance(i, gen, dis, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FD60FBE8B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 5\n",
    "\n",
    "discriminator = define_discriminator_model()\n",
    "generator = define_generator(latent_dim)\n",
    "\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "\n",
    "# train gan_model\n",
    "train_gan(generator, discriminator, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
